**Pré-requis**

```{r include=FALSE}
packages <- c("astsa", "aTSA", "forecast", "fUnitRoots", "MASS", "xts")
installed_packages <- packages %in% rownames(installed.packages())

if (any(installed_packages == FALSE)) {install.packages(packages[!installed_packages])}
invisible(lapply(packages, library, character.only = TRUE))

rm(installed_packages, packages)
```

**Téléchargement puis extraction des données**

Série traitée : Indice CVS-CJO de la production industrielle dans l'industrie pharmaceutique (base 100 en 2021)

```{r include=FALSE}
file_url <- "https://www.insee.fr/fr/statistiques/serie/telecharger/csv/010767832?ordre=antechronologique&transposition=donneescolonne&periodeDebut=1&anneeDebut=1990&periodeFin=2&anneeFin=2024&revision=sansrevisions"
name <- "Production de l'industrie pharmaceutique"

local_file_name <- "data.zip"
download.file(file_url, local_file_name, mode = "wb", quiet = TRUE)

file_list <- unzip(local_file_name)
file.rename(file_list[2], "valeurs_mensuelles.csv")

file.remove("data.zip")
file_list[2] <- sub("^\\.\\/", "", file_list[2])
file_list[2] <- sub("/valeurs_mensuelles\\.csv$", "", file_list[2]) 
unlink(file_list[2], recursive = TRUE)

rm(file_url, local_file_name, file_list)
```

**Conversion au format Zoo**

```{r}
data <- read.csv("valeurs_mensuelles.csv", sep = ";")
data <- data[-c(1:3), -3]
colnames(data) <- c("dates", "values")

data <- data[order(data$dates), ]
rownames(data) <- NULL

data$dates <- as.yearmon(data$dates)
data$values <- as.numeric(data$values)

raw_series <- zoo(data$values, order.by=data$dates)
```

# Partie I : données

## 1. Représentation de la série

```{r}
plot(raw_series, main = name, xlab = "Dates", ylab = "Valeurs")
plot(decompose(raw_series))
```

Trois observations : une tendance linéaire croissante, une augmentation de la variance au cours du temps, pas de saisonnalité.

## 2. Stationnarisation

On commence par une transformation logarithmique pour corriger l'hétéroscédasticité.

```{r}
log_series <- log(raw_series)
plot(decompose(log_series))
```

On différencie ensuite à l'ordre 1 pour éliminer la tendance.

```{r}
diff_series <- diff(log_series, 1)
plot(decompose(diff_series))
```

On vérifie que le résultat convient à l'aide de tests de stationnarité : c'est bon, sauf pour le KPSS sans drift ni trend (?).

```{r eval=FALSE}
adf <- adf.test(coredata(diff_series), nlag = 24, output = TRUE)
pp.test(coredata(diff_series), lag.short = TRUE, output = TRUE)
kpss.test(coredata(diff_series), lag.short = TRUE, output = TRUE)
```

## 3. Comparaison de la série initiale et de la série transformée

```{r}
# par(mfrow = c(2, 1)) # bugue...
plot(raw_series, main = "", xlab = "Dates", ylab = "Valeurs")
plot(diff_series, main = "", xlab = "Dates", ylab = "Valeurs")
```

# Partie II : Modèle ARMA

## 1. Identification des paramètres

```{r}
# par(mfrow = c(2, 1)) # bugue...
acf(diff_series, main = paste(name))
pacf(diff_series, main = paste(name))
```

On retient qmax=1 et pmax = 6.

## 2. Estimation des modèles

```{r}
pmax <- 6
qmax <- 1
mat <- matrix(NA, nrow=pmax+1,ncol=qmax+1) # matrice vide à remplir
rownames(mat) <- paste0("p=",0:pmax) # renomme les lignes
colnames(mat) <- paste0("q=",0:qmax) # renomme les colonnes
AICs <- mat # matrice des AIC non remplie
BICs <- mat # matrice des BIC non remplie

pqs <- expand.grid(0:pmax,0:qmax) # toutes les combinaisons possibles de p et q
for (row in 1:dim(pqs)[1]){ # boucle pour chaque (p,q)
  p <- pqs[row,1] # récupère p
  q <- pqs[row,2] # récupère q
  estim <- try(arima(log_series,c(p,1,q),include.mean = F)) # tente d’estimer l’ARIMA
  AICs[p+1,q+1] <- if (class(estim)=="try-error") NA else estim$aic # assigne l’AIC
  BICs[p+1,q+1] <- if (class(estim)=="try-error") NA else BIC(estim) # assigne le BIC
}

AICs # affiche les AICs
BICs # affiche les BICs
```

Le modèle minimisant l'AIC est un ARMA(4,0) mais celui minimisant le BIC est un ARMA(0,1) : logique puisque le BIC pénalise davantage la complexité.

```{r}
arima410 <- arima(log_series,c(4,1,0),include.mean=F)
arima011 <- arima(log_series,c(0,1,1),include.mean=F)
```

## 3. Tests de validité et d'ajustement

Pour l'ajustement, on vérifie la significativité des coefficients les plus élevés : c'est bon pour les deux modèles.

```{r}
signif <- function(estim){
  coef <- estim$coef
  se <- sqrt(diag(estim$var.coef))
  t <- coef/se
  pval <- (1-pnorm(abs(t)))*2
  return(rbind(coef,se,pval))
}

signif(arima410)
signif(arima011)
```

Pour la validité, c'est-à-dire la non-autocorrélation des résidus, on utilise le test Portemanteau. Il conduit à rejeter l'ARMA(4,1).

```{r}
Qtests <- function(series, k, fitdf = 0) {
  pvals <- apply(matrix(1:k), 1, FUN = function(l) {
    pval <- if (l <= fitdf) NA else Box.test(series, lag = l, type = "Ljung-Box", fitdf = fitdf)$p.value
    return(c("lag" = l,"pval" = pval))
  })
  return(t(pvals))
}

Qtests(arima410$residuals, 24, fitdf=1)
Qtests(arima011$residuals, 24, fitdf=1)
```
# Partie III : Prévision


