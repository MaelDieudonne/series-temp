**Pré-requis**

```{r include=FALSE}
packages <- c("astsa", "aTSA", "forecast", "fUnitRoots", "ggplot2", "MASS", "xts")
installed_packages <- packages %in% rownames(installed.packages())

if (any(installed_packages == FALSE)) {install.packages(packages[!installed_packages])}
invisible(lapply(packages, library, character.only = TRUE))

rm(installed_packages, packages)
```

**Téléchargement puis extraction des données**

Série traitée : Indice CVS-CJO de la production industrielle dans l'industrie pharmaceutique (base 100 en 2021)

```{r include=FALSE}
file_url <- "https://www.insee.fr/fr/statistiques/serie/telecharger/csv/010767832?ordre=antechronologique&transposition=donneescolonne&periodeDebut=1&anneeDebut=1990&periodeFin=2&anneeFin=2024&revision=sansrevisions"
name <- "Production de l'industrie pharmaceutique"

local_file_name <- "data.zip"
download.file(file_url, local_file_name, mode = "wb", quiet = TRUE)

file_list <- unzip(local_file_name)
file.rename(file_list[2], "valeurs_mensuelles.csv")

file.remove("data.zip")
file_list[2] <- sub("^\\.\\/", "", file_list[2])
file_list[2] <- sub("/valeurs_mensuelles\\.csv$", "", file_list[2]) 
unlink(file_list[2], recursive = TRUE)

rm(file_url, local_file_name, file_list)
```

**Conversion au format ts**

```{r}
data <- read.csv("valeurs_mensuelles.csv", sep = ";")
data <- data[-c(1:3), -3]
colnames(data) <- c("dates", "values")

data <- data[order(data$dates), ]
rownames(data) <- NULL

data$dates <- as.yearmon(data$dates)
data$values <- as.numeric(data$values)

# On tronque la série après 2019 pour éviter les flucutations intempestives dues au covid, surtout compte-tenu de l'objet de notre série.
data <- data[1:which(data$dates == "Dec 2019"), ]

raw_series <- ts(data$values, start = min(data$dates), frequency = 12)
```

# Partie I : données

## 1. Représentation de la série

```{r}
plot(raw_series, main = name, xlab = "Dates", ylab = "Valeurs")
plot(decompose(raw_series))
```

Trois observations : une tendance linéaire croissante, une augmentation de la variance au cours du temps, aucune de saisonnalité. Pas besoin de régression linéaire pour objectiver la tendance, elle est vraiment flagrante.

## 2. Stationnarisation

On commence par une transformation logarithmique pour corriger l'hétéroscédasticité.

```{r}
log_series <- log(raw_series)
plot(decompose(log_series))
```

On différencie ensuite à l'ordre 1 pour éliminer la tendance.

```{r}
diff_series <- diff(log_series, 1)
plot(decompose(diff_series))
```

On vérifie que le résultat convient à l'aide de tests de stationnarité. La tendance a disparu mais il reste une légère dérive. On retient donc les tests avec drift sans trend. La série passe les trois.

```{r eval=FALSE}
cat(paste("Moyenne de la série :", mean(diff_series), "\n"))

adf <- adf.test(coredata(diff_series), nlag = 24, output = FALSE)
pp <- pp.test(coredata(diff_series), lag.short = TRUE, output = FALSE)
kpss <- kpss.test(coredata(diff_series), lag.short = TRUE, output = FALSE)

cat("\nTest ADF with drift no trend\n")
print(adf$type2)
cat("\nTest PP with drift no trend\n")
print(pp["type 2", ])
cat("\nTest KPSS with drift no trend\n")
print(kpss["type 2", ])
```

## 3. Comparaison de la série initiale et de la série transformée

```{r}
# par(mfrow = c(2, 1)) 
plot(raw_series, main = "Série initiale", xlab = "", ylab = "")
plot(diff_series, main = "Série transformée", xlab = "", ylab = "")
```

# Partie II : Modèle ARMA

## 1. Identification des paramètres

```{r}
# par(mfrow = c(2, 1))
acf(diff_series, main = paste(name))
pacf(diff_series, main = paste(name))
```

On retient qmax=1 et pmax = 11. Ce n'est pas l'approche la plus parcimonieuse, mais le pic à l=11 est quand même bien prononcé (et pas à 12, auquel cas on se serait plutôt inquiété d'un problème de saisonnalité).

## 2. Estimation des modèles

Par les critères d'information : le modèle minimisant l'AIC est un ARMA(11,0) mais celui minimisant le BIC est un ARMA(0,1) (logique puisque le BIC pénalise davantage la complexité).

```{r}
pmax <- 11
qmax <- 1
mat <- matrix(NA, nrow=pmax+1,ncol=qmax+1) # matrice vide à remplir
rownames(mat) <- paste0("p=",0:pmax) # renomme les lignes
colnames(mat) <- paste0("q=",0:qmax) # renomme les colonnes
AICs <- mat # matrice des AIC non remplie
BICs <- mat # matrice des BIC non remplie

pqs <- expand.grid(0:pmax,0:qmax) # toutes les combinaisons possibles de p et q
for (row in 1:dim(pqs)[1]){ # boucle pour chaque (p,q)
  p <- pqs[row,1] # récupère p
  q <- pqs[row,2] # récupère q
  estim <- try(arima(log_series,c(p,1,q),include.mean = F)) # tente d’estimer l’ARIMA
  AICs[p+1,q+1] <- if (class(estim)=="try-error") NA else estim$aic # assigne l’AIC
  BICs[p+1,q+1] <- if (class(estim)=="try-error") NA else BIC(estim) # assigne le BIC
}

print(AICs)
lowest_cell <- which(as.matrix(AICs) == min(as.matrix(AICs)), arr.ind = TRUE)
p <- rownames(AICs)[lowest_cell[1]]
p <- sub("^p=", "", p)
q <- colnames(AICs)[lowest_cell[2]]
q <- sub("^q=", "", q)
cat(paste0("\nBest model according to AIC is an ARMA(",p, ",", q, ").\n\n"))

print(BICs)
lowest_cell <- which(as.matrix(BICs) == min(as.matrix(BICs)), arr.ind = TRUE)
p <- rownames(BICs)[lowest_cell[1]]
p <- sub("^p=", "", p)
q <- colnames(BICs)[lowest_cell[2]]
q <- sub("^q=", "", q)
cat(paste0("\nBest model according to BIC is an ARMA(",p, ",", q, ")."))
```

Par l'erreur de prédiction : le modèle qui la minimise, sur les 5 dernières valeurs, est un ARMA(0,0), donc un bruit blanc.

```{r}
values <- data$values[(nrow(data) - 4):nrow(data)]
pqs <- expand.grid(0:pmax,0:qmax)
mat <- matrix(NA, nrow=pmax+1, ncol=qmax+1)
rownames(mat) <- paste0("p=",0:pmax)
colnames(mat) <- paste0("q=",0:qmax)
pred_error <- mat 
for (row in 1:dim(pqs)[1]){
  p <- pqs[row,1]
  q <- pqs[row,2]
  pred_error[p+1,q+1] <- sqrt(mean((predict(arima(diff_series,c(p,1,q),include.mean=F),n.ahead = 5)$pred[1:5] - values)^2))
}

pred_error
lowest_cell <- which(as.matrix(pred_error) == min(as.matrix(pred_error)), arr.ind = TRUE)
p <- rownames(BICs)[lowest_cell[1]]
p <- sub("^p=", "", p)
q <- colnames(BICs)[lowest_cell[2]]
q <- sub("^q=", "", q)
cat(paste0("\nBest model according to prediction error is an ARMA(",p, ",", q, ")."))
```

```{r}
arima1110 <- arima(log_series,c(11,1,0),include.mean=F)
arima011 <- arima(log_series,c(0,1,1),include.mean=F)
arima010 <- arima(log_series,c(0,1,0),include.mean=F)
```

## 3. Tests de validité et d'ajustement

Pour l'ajustement, on vérifie la significativité des coefficients les plus élevés : l'ARMA(11,0) et l'ARMA(0,1) passent ce test (qui n'a évidemment pas de sens pour un bruit blanc).

```{r}
signif <- function(estim){
  coef <- estim$coef
  se <- sqrt(diag(estim$var.coef))
  t <- coef/se
  pval <- (1-pnorm(abs(t)))*2
  return(rbind(coef, se, pval))
}

signif(arima1110)
cat("\n")
signif(arima011)
```

Pour la validité, c'est-à-dire la non-autocorrélation des résidus, on utilise le test Portemanteau. Il conduit à rejeter l'ARMA(0,1) et l'ARMA(0,0).

```{r}
Qtests <- function(series, k, fitdf = 0) {
  pvals <- apply(matrix(1:k), 1, FUN = function(l) {
    pval <- if (l <= fitdf) NA else Box.test(series, lag = l, type = "Ljung-Box", fitdf = fitdf)$p.value
    return(c("lag" = l,"pval" = pval))
  })
  return(t(pvals))
}

cat("ARMA(11,0)\n")
Qtests(arima1110$residuals, 24, fitdf=11)
cat("\nARMA(0,1)\n")
Qtests(arima011$residuals, 24, fitdf=1)
cat("\nARMA(0,0)\n")
Qtests(arima010$residuals, 24, fitdf=0)
```

Vérification avec la fonction auto.arima() : elle retient l'ARMA(0,1) qu'on vient d'écarter.

```{r}
auto.arima(log_series, trace = TRUE)
```

# Partie III : Prévision

Nous allons bien nous amuser avec un ARMA(11,0) ! On élimine les coefficients ar5, ar6 et ar7 qui n'étaient pas significatifs plus haut.

```{r}
# Chunk pour réinitier
data <- read.csv("valeurs_mensuelles.csv", sep = ";")
data <- data[-c(1:3), -3]
colnames(data) <- c("dates", "values")
data <- data[order(data$dates), ]
rownames(data) <- NULL
data$dates <- as.yearmon(data$dates)
data$values <- as.numeric(data$values)
data <- data[1:which(data$dates == "Dec 2019"), ]
raw_series <- ts(data$values, start = min(data$dates), frequency = 12)
log_series <- log(raw_series)
arima1110 <- arima(log_series,c(11,1,0),include.mean=F)

data$log_values <- log(data$values)
```

```{r}
T <- as.numeric(nrow(data))
prevT1 <- 0
for (i in c(1:4, 8:11)) {
  prevT1 <- prevT1 + as.numeric(arima1110$coef[paste0("ar", i)]) * data$log_values[T - i + 1]}
prevT1_CIl <- prevT1 - 1.96*sqrt(arima1110$sigma2)
prevT1_CIu <- prevT1 + 1.96*sqrt(arima1110$sigma2)
data <- rbind(data, c(max(data$dates)+1/12, exp(prevT1), prevT1))
# R s'obstine à arrondir les valeurs , je ne comprends pas pourquoi :-(

T <- as.numeric(nrow(data))
prevT2 <- 0
for (i in c(1:4, 8:11)) {
  prevT2 <- prevT2 + as.numeric(arima1110$coef[paste0("ar", i)]) * data$log_values[T - i + 1]}
prevT2_CIl <- prevT2 - 1.96*sqrt(arima1110$sigma2)
prevT2_CIu <- prevT2 + 1.96*sqrt(arima1110$sigma2)
data <- rbind(data, c(max(data$dates)+1/12, exp(prevT2), prevT2))

T <- as.numeric(nrow(data))
t <- T - 10
dates <- seq(as.Date(min(data$dates[t:T])), by = "month", length.out = 11)
values <- c(data$log_values[t:T])
ICl <- c(rep(NA, 9), prevT1_CIl, prevT2_CIl)
ICu <- c(rep(NA, 9), prevT1_CIu, prevT2_CIu)
df <- data.frame(dates, values, ICl, ICu)

ggplot(data = df, aes(x=dates, y=values)) +
  geom_line() +
  geom_ribbon(aes(ymin = ICl, ymax = ICu), fill = "lightgray", alpha = 0.5) +
  geom_line(aes(y = ICl), color = "blue", linetype = "dashed") +
  geom_line(aes(y = ICu), color = "red", linetype = "dashed") +
  labs(title = "Prévisions à t+2", x = "", y = "") +
  theme_minimal()
```

```{r}
# Legacy
data$log_values <- log(data$values)

prevT1 = as.numeric(
  data$log_values[nrow(data)] +
  arima011$coef["ma1"] * arima011$residuals[length(arima011$residuals)])
prevT1_lower5 = as.numeric(prevT1 - 1.96*sqrt(arima011$sigma2))
prevT1_upper5 = as.numeric(prevT1 + 1.96*sqrt(arima011$sigma2))

prevT2 = as.numeric(prevT1 + arima011$coef["ma1"] * arima011$residuals[length(arima011$residuals)])
prevT2_lower5 = as.numeric(prevT1_lower5 - 1.96*sqrt(arima011$sigma2))
prevT2_upper5 = as.numeric(prevT1_upper5 + 1.96*sqrt(arima011$sigma2))

dates <- seq(as.Date(min(data$dates[395:410])), by = "month", length.out = 18)
values <- exp(c(data$log_values[395:410], prevT1, prevT2))
ICl <- exp(c(rep(NA, 16), prevT1_lower5, prevT2_lower5))
ICu <- exp(c(rep(NA, 16), prevT1_upper5, prevT2_upper5))
df <- data.frame(dates, values, ICl, ICu)

ggplot(data = df, aes(x=dates, y=values)) +
  geom_line() +
  geom_ribbon(aes(ymin = ICl, ymax = ICu), fill = "lightgray", alpha = 0.5) +
  geom_line(aes(y = ICl), color = "blue", linetype = "dashed") +
  geom_line(aes(y = ICu), color = "red", linetype = "dashed") +
  labs(title = "Prévisions à t+2", x = "", y = "") +
  theme_minimal()
```

```{r}
# Legacy
forecast_values <- forecast(arima011, h = 50, level = 95)

forecast_values$x <- exp(forecast_values$x)
forecast_values$mean <- exp(forecast_values$mean)
forecast_values$lower <- exp(forecast_values$lower)
forecast_values$upper <- exp(forecast_values$upper)

plot(forecast_values, main = "Time Series Forecast", xlab = "Time", ylab = "Values")
lines(log_series, col = "blue")
lines(forecast_values$mean, col = "red")
lines(forecast_values$upper, col = "green", lty = 2)
lines(forecast_values$lower, col = "green", lty = 2)
legend("topleft", legend = c("Original", "Forecast", "95% Confidence Interval"), col = c("blue", "red", "green"), lty = c(1, 1, 2))
```
